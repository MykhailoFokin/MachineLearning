{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_classification_with_MSE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MykhailoFokin/MachineLearning/blob/master/simple_classification_with_MSE(float).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyPNlcb6nKgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import fnmatch\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import explained_variance_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVOSURUpYlBh",
        "colab_type": "code",
        "outputId": "d460c4f5-ff69-41bd-d140-e272142f28d4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Copy images from repo to colab\n",
        "!git clone https://github.com/SilvesterHsu/ORLFaceRecognition-PCA.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ORLFaceRecognition-PCA'...\n",
            "remote: Enumerating objects: 604, done.\u001b[K\n",
            "Receiving objects:   0% (1/604)   \rReceiving objects:   1% (7/604)   \rReceiving objects:   2% (13/604)   \rReceiving objects:   3% (19/604)   \rReceiving objects:   4% (25/604)   \rReceiving objects:   5% (31/604)   \rReceiving objects:   6% (37/604)   \rReceiving objects:   7% (43/604)   \rReceiving objects:   8% (49/604)   \rReceiving objects:   9% (55/604)   \rReceiving objects:  10% (61/604)   \rReceiving objects:  11% (67/604)   \rReceiving objects:  12% (73/604)   \rReceiving objects:  13% (79/604)   \rReceiving objects:  14% (85/604)   \rReceiving objects:  15% (91/604)   \rReceiving objects:  16% (97/604)   \rReceiving objects:  17% (103/604)   \rReceiving objects:  18% (109/604)   \rReceiving objects:  19% (115/604)   \rReceiving objects:  20% (121/604)   \rReceiving objects:  21% (127/604)   \rReceiving objects:  22% (133/604)   \rReceiving objects:  23% (139/604)   \rReceiving objects:  24% (145/604)   \rReceiving objects:  25% (151/604)   \rReceiving objects:  26% (158/604)   \rReceiving objects:  27% (164/604)   \rReceiving objects:  28% (170/604)   \rReceiving objects:  29% (176/604)   \rReceiving objects:  30% (182/604)   \rReceiving objects:  31% (188/604)   \rReceiving objects:  32% (194/604)   \rReceiving objects:  33% (200/604)   \rReceiving objects:  34% (206/604)   \rReceiving objects:  35% (212/604)   \rReceiving objects:  36% (218/604)   \rReceiving objects:  37% (224/604)   \rReceiving objects:  38% (230/604)   \rReceiving objects:  39% (236/604)   \rReceiving objects:  40% (242/604)   \rReceiving objects:  41% (248/604)   \rReceiving objects:  42% (254/604)   \rReceiving objects:  43% (260/604)   \rReceiving objects:  44% (266/604)   \rReceiving objects:  45% (272/604)   \rReceiving objects:  46% (278/604)   \rReceiving objects:  47% (284/604)   \rReceiving objects:  48% (290/604)   \rReceiving objects:  49% (296/604)   \rReceiving objects:  50% (302/604)   \rReceiving objects:  51% (309/604)   \rReceiving objects:  52% (315/604)   \rReceiving objects:  53% (321/604)   \rReceiving objects:  54% (327/604)   \rReceiving objects:  55% (333/604)   \rReceiving objects:  56% (339/604)   \rReceiving objects:  57% (345/604)   \rReceiving objects:  58% (351/604)   \rReceiving objects:  59% (357/604)   \rReceiving objects:  60% (363/604)   \rReceiving objects:  61% (369/604)   \rReceiving objects:  62% (375/604)   \rReceiving objects:  63% (381/604)   \rReceiving objects:  64% (387/604)   \rReceiving objects:  65% (393/604)   \rReceiving objects:  66% (399/604)   \rReceiving objects:  67% (405/604)   \rReceiving objects:  68% (411/604)   \rReceiving objects:  69% (417/604)   \rReceiving objects:  70% (423/604)   \rReceiving objects:  71% (429/604)   \rReceiving objects:  72% (435/604)   \rReceiving objects:  73% (441/604)   \rReceiving objects:  74% (447/604)   \rReceiving objects:  75% (453/604)   \rReceiving objects:  76% (460/604)   \rReceiving objects:  77% (466/604)   \rReceiving objects:  78% (472/604)   \rReceiving objects:  79% (478/604)   \rReceiving objects:  80% (484/604)   \rReceiving objects:  81% (490/604)   \rReceiving objects:  82% (496/604)   \rReceiving objects:  83% (502/604)   \rremote: Total 604 (delta 0), reused 0 (delta 0), pack-reused 604\u001b[K\n",
            "Receiving objects:  84% (508/604)   \rReceiving objects:  85% (514/604)   \rReceiving objects:  86% (520/604)   \rReceiving objects:  87% (526/604)   \rReceiving objects:  88% (532/604)   \rReceiving objects:  89% (538/604)   \rReceiving objects:  90% (544/604)   \rReceiving objects:  91% (550/604)   \rReceiving objects:  92% (556/604)   \rReceiving objects:  93% (562/604)   \rReceiving objects:  94% (568/604)   \rReceiving objects:  95% (574/604)   \rReceiving objects:  96% (580/604)   \rReceiving objects:  97% (586/604)   \rReceiving objects:  98% (592/604)   \rReceiving objects:  99% (598/604)   \rReceiving objects: 100% (604/604)   \rReceiving objects: 100% (604/604), 3.59 MiB | 27.25 MiB/s, done.\n",
            "Resolving deltas:   0% (0/93)   \rResolving deltas:   3% (3/93)   \rResolving deltas:   7% (7/93)   \rResolving deltas:  17% (16/93)   \rResolving deltas:  27% (26/93)   \rResolving deltas:  29% (27/93)   \rResolving deltas:  30% (28/93)   \rResolving deltas:  32% (30/93)   \rResolving deltas:  47% (44/93)   \rResolving deltas:  84% (79/93)   \rResolving deltas: 100% (93/93)   \rResolving deltas: 100% (93/93), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4mtTesG2RiJ",
        "colab_type": "code",
        "outputId": "6135a5df-4a31-46fa-93ee-74af3195ada3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 826
        }
      },
      "source": [
        "dataset = []\n",
        "indexes = []\n",
        "test_matrix = []\n",
        "train_matrix = []\n",
        "test_labels = []\n",
        "train_labels = []\n",
        "dataset_shuffle = False\n",
        "stratify = None\n",
        "random_state = 42\n",
        "path_x=[]\n",
        "\n",
        "# read folder structure with files and put it to collection\n",
        "folder = []\n",
        "for i in os.walk(os.path.join('ORLFaceRecognition-PCA','att_faces')):\n",
        "  folder.append(i)\n",
        "\n",
        "for address, dirs, files in folder:\n",
        "  for file in fnmatch.filter(files, '*.pgm'):\n",
        "    path_x.append(os.path.join(address,file))\n",
        "\n",
        "for file in sorted(path_x, key=lambda x: int(x.split(\"/\",3)[3].rstrip('.pgm')+x.split(\"/\",3)[2].lstrip(\"s\").zfill(2))):\n",
        "\n",
        "  img = cv2.imread(file)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n",
        "  gray = gray.astype(float)\n",
        "  #gray.flatten().reshape(1, 10304)\n",
        "  person = file.split(\"/\",3)[2].lstrip(\"s\")\n",
        "\n",
        "  dataset.append(gray.flatten().reshape(1, 10304))\n",
        "  indexes.append(int(person))\n",
        "\n",
        "for split_mark in range(1, 19):\n",
        "\n",
        "  if split_mark>=10:\n",
        "    dataset_shuffle = True\n",
        "    split_k=split_mark-9\n",
        "  else:\n",
        "    split_k=split_mark\n",
        "\n",
        "  train_matrix, test_matrix, train_labels, test_labels = train_test_split(dataset, indexes, test_size=split_k/10, random_state=random_state, shuffle=dataset_shuffle, stratify=stratify)\n",
        "\n",
        "  estimations_mse = []\n",
        "  estimations_mae = []\n",
        "  estimations_msle = []\n",
        "  estimations_std = []\n",
        "\n",
        "  for test_image in test_matrix:\n",
        "\n",
        "    matrix_mse = []\n",
        "    matrix_mae = []\n",
        "    matrix_msle = []\n",
        "    matrix_std = []\n",
        "\n",
        "    for train_image in train_matrix:\n",
        "\n",
        "      matrix_mse.append(mean_squared_error(test_image, train_image))\n",
        "      matrix_mae.append(mean_absolute_error(test_image, train_image))\n",
        "      matrix_msle.append(mean_squared_log_error(test_image, train_image))\n",
        "      matrix_std.append(np.sqrt(mean_squared_error(test_image, train_image)))\n",
        "\n",
        "    estimations_mse.append(train_labels[np.argmin(matrix_mse)])\n",
        "    estimations_mae.append(train_labels[np.argmin(matrix_mae)])\n",
        "    estimations_msle.append(train_labels[np.argmin(matrix_msle)])\n",
        "    estimations_std.append(train_labels[np.argmin(matrix_std)])\n",
        "\n",
        "  result_mse = np.equal(test_labels, estimations_mse)\n",
        "  result_mae = np.equal(test_labels, estimations_mae)\n",
        "  result_msle = np.equal(test_labels, estimations_msle)\n",
        "  result_std = np.equal(test_labels, estimations_std)\n",
        "\n",
        "  matrix_length = len(result_mse)\n",
        "\n",
        "  evaluation_mse = np.sum(result_mse)/matrix_length\n",
        "  evaluation_mae = np.sum(result_mae)/matrix_length\n",
        "  evaluation_msle = np.sum(result_msle)/matrix_length\n",
        "  evaluation_std = np.sum(result_std)/matrix_length\n",
        "\n",
        "  print('MSE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_mse))\n",
        "  print('MAE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_mae))\n",
        "  print('MSLE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_msle))\n",
        "  print('STD{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_std))\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE.  Train/Test : 90 / 10 - 0.925\n",
            "MAE.  Train/Test : 90 / 10 - 0.925\n",
            "MSLE.  Train/Test : 90 / 10 - 0.925\n",
            "STD.  Train/Test : 90 / 10 - 0.925\n",
            "MSE.  Train/Test : 80 / 20 - 0.950\n",
            "MAE.  Train/Test : 80 / 20 - 0.963\n",
            "MSLE.  Train/Test : 80 / 20 - 0.963\n",
            "STD.  Train/Test : 80 / 20 - 0.950\n",
            "MSE.  Train/Test : 70 / 30 - 0.942\n",
            "MAE.  Train/Test : 70 / 30 - 0.967\n",
            "MSLE.  Train/Test : 70 / 30 - 0.950\n",
            "STD.  Train/Test : 70 / 30 - 0.942\n",
            "MSE.  Train/Test : 60 / 40 - 0.938\n",
            "MAE.  Train/Test : 60 / 40 - 0.975\n",
            "MSLE.  Train/Test : 60 / 40 - 0.938\n",
            "STD.  Train/Test : 60 / 40 - 0.938\n",
            "MSE.  Train/Test : 50 / 50 - 0.900\n",
            "MAE.  Train/Test : 50 / 50 - 0.945\n",
            "MSLE.  Train/Test : 50 / 50 - 0.910\n",
            "STD.  Train/Test : 50 / 50 - 0.900\n",
            "MSE.  Train/Test : 40 / 60 - 0.884\n",
            "MAE.  Train/Test : 40 / 60 - 0.909\n",
            "MSLE.  Train/Test : 40 / 60 - 0.892\n",
            "STD.  Train/Test : 40 / 60 - 0.884\n",
            "MSE.  Train/Test : 30 / 70 - 0.857\n",
            "MAE.  Train/Test : 30 / 70 - 0.879\n",
            "MSLE.  Train/Test : 30 / 70 - 0.850\n",
            "STD.  Train/Test : 30 / 70 - 0.857\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-7eea9413b8e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     56\u001b[0m       \u001b[0mmatrix_mse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m       \u001b[0mmatrix_mae\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_absolute_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m       \u001b[0mmatrix_msle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_log_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m       \u001b[0mmatrix_std\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_image\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_image\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/regression.py\u001b[0m in \u001b[0;36mmean_squared_log_error\u001b[0;34m(y_true, y_pred, sample_weight, multioutput)\u001b[0m\n\u001b[1;32m    317\u001b[0m                          \"targets contain negative values.\")\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 319\u001b[0;31m     return mean_squared_error(np.log1p(y_true), np.log1p(y_pred),\n\u001b[0m\u001b[1;32m    320\u001b[0m                               sample_weight, multioutput)\n\u001b[1;32m    321\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    }
  ]
}