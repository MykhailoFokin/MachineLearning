{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Code_simple_classification_with_normalization.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MykhailoFokin/MachineLearning/blob/master/Code_of_simple_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyPNlcb6nKgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import fnmatch\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVOSURUpYlBh",
        "colab_type": "code",
        "outputId": "1c743ffe-d99f-40e5-cd47-2242d4629a57",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Copy images from repo to colab\n",
        "!git clone https://github.com/SilvesterHsu/ORLFaceRecognition-PCA.git"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ORLFaceRecognition-PCA'...\n",
            "remote: Enumerating objects: 604, done.\u001b[K\n",
            "remote: Total 604 (delta 0), reused 0 (delta 0), pack-reused 604\u001b[K\n",
            "Receiving objects: 100% (604/604), 3.59 MiB | 7.39 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljk0ib0q9MAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define block of different types of normalization\n",
        "def f_0_1(a,x_min,x_max):\n",
        "  return (a-x_min)/(x_max-x_min)\n",
        "\n",
        "vectorized_f_0_1 = np.vectorize(f_0_1)\n",
        "\n",
        "def f__1_1(a,x_min,x_max):\n",
        "  return 2*((a-x_min)/(x_max-x_min))-1\n",
        "\n",
        "vectorized_f__1_1 = np.vectorize(f__1_1)\n",
        "\n",
        "def f_std(a,x_mean,x_std):\n",
        "  return (a-x_mean)/x_std\n",
        "\n",
        "vectorized_f_std = np.vectorize(f_std)\n",
        "\n",
        "def f_min_max_0_1(a):\n",
        "  return vectorized_f_0_1(a,a.min(),a.max())\n",
        "\n",
        "def f_min_max_1_1(a):\n",
        "  return vectorized_f__1_1(a,a.min(),a.max())\n",
        "\n",
        "def f_mean_std(a):\n",
        "  return vectorized_f__1_1(a,np.mean(a),np.std(a))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4mtTesG2RiJ",
        "colab_type": "code",
        "outputId": "2c4eea26-29d1-4c4e-cd56-d5b94390e86c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        }
      },
      "source": [
        "dataset = []\n",
        "#dataset_images = []\n",
        "indexes = []\n",
        "test_matrix = []\n",
        "train_matrix = []\n",
        "test_labels = []\n",
        "train_labels = []\n",
        "dataset_shuffle = False\n",
        "stratify = None\n",
        "random_state = 42\n",
        "path_x=[]\n",
        "img_list = []\n",
        "train_images = []\n",
        "print_difference_photos = False\n",
        "scaler_enum = ['s0_1','s_1_1','s_std']\n",
        "np_axis = 1; # 0 - vertical, 1 - horizontal\n",
        "\n",
        "# read folder structure with files and put it to collection\n",
        "folder = []\n",
        "for i in os.walk(os.path.join('ORLFaceRecognition-PCA','att_faces')):\n",
        "  folder.append(i)\n",
        "\n",
        "for address, dirs, files in folder:\n",
        "  for file in fnmatch.filter(files, '*.pgm'):\n",
        "    path_x.append(os.path.join(address,file))\n",
        "\n",
        "for file in sorted(path_x, key=lambda x: int(x.split(\"/\",3)[3].rstrip('.pgm')+x.split(\"/\",3)[2].lstrip(\"s\").zfill(2))):\n",
        "\n",
        "  img = cv2.imread(file)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n",
        "  gray = gray.astype(float)\n",
        "  person = file.split(\"/\",3)[2].lstrip(\"s\")\n",
        "\n",
        "  #dataset_images.append(img)\n",
        "  #dataset.append(gray.flatten().reshape(1, 10304))\n",
        "  dataset.append(gray.flatten())\n",
        "  indexes.append(int(person))\n",
        "  img_list.append(file.split(\"/\",3)[3].rstrip('.pgm'))\n",
        "\n",
        "# Normalization block\n",
        "# numbers to range 0 - 1\n",
        "dataset = np.array(dataset)\n",
        "#dataset=dataset.swapaxes(0,1)\n",
        "\n",
        "dataset = np.apply_along_axis(f_min_max_0_1,np_axis,dataset)\n",
        "#dataset = np.apply_along_axis(f_min_max__1_1,np_axis,dataset)\n",
        "#dataset = np.apply_along_axis(f_mean_std,np_axis,dataset)\n",
        "#print(np.apply_along_axis(f_min_max,np_axis,dataset))\n",
        "\n",
        "\n",
        "# Without shuffle 1,10\n",
        "# With shuffle 10,19\n",
        "# Both 1,19\n",
        "#for split_mark in range(1, 19):\n",
        "for split_mark in range(1, 10):\n",
        "\n",
        "  if split_mark>=10:\n",
        "    dataset_shuffle = True\n",
        "    split_k=split_mark-9\n",
        "  else:\n",
        "    split_k=split_mark\n",
        "\n",
        "  train_matrix, test_matrix, train_labels, test_labels = train_test_split(dataset, indexes, test_size=split_k/10, random_state=random_state, shuffle=dataset_shuffle, stratify=stratify)\n",
        "\n",
        "  estimations_mse = []\n",
        "  estimations_mae = []\n",
        "  #estimations_msle = []\n",
        "  #estimations_std = []\n",
        "\n",
        "  train_images = []\n",
        "\n",
        "  for test_image in test_matrix:\n",
        "\n",
        "    matrix_mse = []\n",
        "    matrix_mae = []\n",
        "    #matrix_msle = []\n",
        "    #matrix_std = []\n",
        "\n",
        "    for train_image in train_matrix:\n",
        "\n",
        "      matrix_mse.append(mean_squared_error(test_image, train_image))\n",
        "      matrix_mae.append(mean_absolute_error(test_image, train_image))\n",
        "      #matrix_msle.append(mean_squared_log_error(test_image, train_image))\n",
        "      #matrix_std.append(np.sqrt(mean_squared_error(test_image, train_image)))\n",
        "\n",
        "    estimations_mse.append(train_labels[np.argmin(matrix_mse)])\n",
        "    estimations_mae.append(train_labels[np.argmin(matrix_mae)])\n",
        "    #estimations_msle.append(train_labels[np.argmin(matrix_msle)])\n",
        "    #estimations_std.append(train_labels[np.argmin(matrix_std)])\n",
        "\n",
        "    train_images.append(train_matrix[np.argmin(matrix_mse)]) # for print\n",
        "\n",
        "  result_mse = np.equal(test_labels, estimations_mse)\n",
        "  result_mae = np.equal(test_labels, estimations_mae)\n",
        "  #result_msle = np.equal(test_labels, estimations_msle)\n",
        "  #result_std = np.equal(test_labels, estimations_std)\n",
        "\n",
        "  matrix_length = len(result_mse)\n",
        "\n",
        "  evaluation_mse = np.sum(result_mse)/matrix_length\n",
        "  evaluation_mae = np.sum(result_mae)/matrix_length\n",
        "  #evaluation_msle = np.sum(result_msle)/matrix_length\n",
        "  #evaluation_std = np.sum(result_std)/matrix_length\n",
        "\n",
        "  print('MSE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_mse))\n",
        "  print('MAE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_mae))\n",
        "  #print('MSLE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_msle))\n",
        "  #print('STD{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_std))\n",
        "\n",
        "  # print dataset distribution\n",
        "#  if dataset_shuffle:\n",
        "#    plt.hist(test_labels, bins=range(1, len(list(set(test_labels))) + 2))\n",
        "#    plt.yticks(np.arange(0, len(list(set(img_list))) + 1, 1))\n",
        "#    plt.show()\n",
        "  \n",
        "  if print_difference_photos:\n",
        "    for img_ind in range(1,len(result_mse)):\n",
        "      if result_mse[img_ind]==False:\n",
        "        img_src = test_matrix[img_ind].reshape(112,92)\n",
        "        print(\"Index {}, test:\", img_ind)\n",
        "        print(\"Index {}, train:\", img_ind)\n",
        "        img_train = train_images[img_ind].reshape(112,92)\n",
        "        plt.subplot(1,2,1),plt.imshow(img_src)\n",
        "        plt.title(\"Test photo\")\n",
        "        plt.subplot(1,2,2),plt.imshow(img_train)\n",
        "        plt.title(\"Train photo\")\n",
        "        plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE.  Train/Test : 90 / 10 - 0.925\n",
            "MAE.  Train/Test : 90 / 10 - 0.925\n",
            "MSE.  Train/Test : 80 / 20 - 0.938\n",
            "MAE.  Train/Test : 80 / 20 - 0.963\n",
            "MSE.  Train/Test : 70 / 30 - 0.942\n",
            "MAE.  Train/Test : 70 / 30 - 0.958\n",
            "MSE.  Train/Test : 60 / 40 - 0.931\n",
            "MAE.  Train/Test : 60 / 40 - 0.963\n",
            "MSE.  Train/Test : 50 / 50 - 0.895\n",
            "MAE.  Train/Test : 50 / 50 - 0.935\n",
            "MSE.  Train/Test : 40 / 60 - 0.879\n",
            "MAE.  Train/Test : 40 / 60 - 0.900\n",
            "MSE.  Train/Test : 30 / 70 - 0.843\n",
            "MAE.  Train/Test : 30 / 70 - 0.854\n",
            "MSE.  Train/Test : 20 / 80 - 0.809\n",
            "MAE.  Train/Test : 20 / 80 - 0.834\n",
            "MSE.  Train/Test : 10 / 90 - 0.700\n",
            "MAE.  Train/Test : 10 / 90 - 0.719\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}