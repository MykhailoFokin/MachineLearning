{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of simple_classification_with_MSE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MykhailoFokin/MachineLearning/blob/master/Code_of_simple_classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyPNlcb6nKgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import fnmatch\n",
        "import numpy as np\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import explained_variance_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVOSURUpYlBh",
        "colab_type": "code",
        "outputId": "b2662da8-38a5-4d59-e20b-c3308d1a9bfd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Copy images from repo to colab\n",
        "!git clone https://github.com/SilvesterHsu/ORLFaceRecognition-PCA.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ORLFaceRecognition-PCA'...\n",
            "remote: Enumerating objects: 604, done.\u001b[K\n",
            "remote: Total 604 (delta 0), reused 0 (delta 0), pack-reused 604\u001b[K\n",
            "Receiving objects: 100% (604/604), 3.59 MiB | 8.14 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ljk0ib0q9MAS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define block of different types of normalization"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4mtTesG2RiJ",
        "colab_type": "code",
        "outputId": "ea8a8b03-9b96-4f37-bd46-05b37ef806db",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "dataset = []\n",
        "#dataset_images = []\n",
        "indexes = []\n",
        "test_matrix = []\n",
        "train_matrix = []\n",
        "test_labels = []\n",
        "train_labels = []\n",
        "dataset_shuffle = False\n",
        "stratify = None\n",
        "random_state = 42\n",
        "path_x=[]\n",
        "img_list = []\n",
        "train_images = []\n",
        "print_difference_photos = False\n",
        "scaler_enum = ['s0_1','s_1_1','s_std','s_min_max']\n",
        "\n",
        "# read folder structure with files and put it to collection\n",
        "folder = []\n",
        "for i in os.walk(os.path.join('ORLFaceRecognition-PCA','att_faces')):\n",
        "  folder.append(i)\n",
        "\n",
        "for address, dirs, files in folder:\n",
        "  for file in fnmatch.filter(files, '*.pgm'):\n",
        "    path_x.append(os.path.join(address,file))\n",
        "\n",
        "for file in sorted(path_x, key=lambda x: int(x.split(\"/\",3)[3].rstrip('.pgm')+x.split(\"/\",3)[2].lstrip(\"s\").zfill(2))):\n",
        "\n",
        "  img = cv2.imread(file)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n",
        "  gray = gray.astype(float)\n",
        "  person = file.split(\"/\",3)[2].lstrip(\"s\")\n",
        "\n",
        "  #dataset_images.append(img)\n",
        "  #dataset.append(gray.flatten().reshape(1, 10304))\n",
        "  dataset.append(gray.flatten())\n",
        "  indexes.append(int(person))\n",
        "  img_list.append(file.split(\"/\",3)[3].rstrip('.pgm'))\n",
        "\n",
        "# Normalization block\n",
        "# numbers to range 0 - 1\n",
        "\n",
        "dataset = np.array(dataset)\n",
        "#print(dataset.shape)\n",
        "print(dataset)\n",
        "dataset_avg = np.average(dataset, axis=0)\n",
        "#print(dataset_avg)\n",
        "def f_0_1(a,x_min,x_max,x_avg):\n",
        "  \"\"\"Average first and last element of a 1-D array\"\"\"\n",
        "  return a/x_max if a > x_avg else a/x_min if 0 < a < x_avg else 0\n",
        "\n",
        "vectorized_f_0_1 = np.vectorize(f_0_1)\n",
        "\n",
        "def f_min_max(a):\n",
        "  min_a = a.min()\n",
        "  max_a = a.max()\n",
        "  avg_a = np.average(a)\n",
        "  print(\"Min {}, Max {}\",x_min, x_max)\n",
        "  return vectorized_f_0_1(a,a.min(),a.max(),np.average(a))\n",
        "\n",
        "\n",
        "\n",
        "#dataset=dataset.swapaxes(0,1)\n",
        "#print(dataset)\n",
        "\n",
        "np.apply_along_axis(f_min_max,0,dataset)\n",
        "print(dataset)\n",
        "#for i in range(0, len(dataset_avg)):\n",
        "#  dataset\n",
        "\n",
        "# std\n",
        "# -1 : 1\n",
        "\n",
        "# Without shuffle 1,10\n",
        "# With shuffle 10,19\n",
        "# Both 1,19\n",
        "#for split_mark in range(1, 19):\n",
        "for split_mark in range(1, 10):\n",
        "\n",
        "  if split_mark>=10:\n",
        "    dataset_shuffle = True\n",
        "    split_k=split_mark-9\n",
        "  else:\n",
        "    split_k=split_mark\n",
        "\n",
        "  train_matrix, test_matrix, train_labels, test_labels = train_test_split(dataset, indexes, test_size=split_k/10, random_state=random_state, shuffle=dataset_shuffle, stratify=stratify)\n",
        "\n",
        "  estimations_mse = []\n",
        "  estimations_mae = []\n",
        "  #estimations_msle = []\n",
        "  #estimations_std = []\n",
        "\n",
        "  train_images = []\n",
        "\n",
        "  for test_image in test_matrix:\n",
        "\n",
        "    matrix_mse = []\n",
        "    matrix_mae = []\n",
        "    #matrix_msle = []\n",
        "    #matrix_std = []\n",
        "\n",
        "    for train_image in train_matrix:\n",
        "\n",
        "      matrix_mse.append(mean_squared_error(test_image, train_image))\n",
        "      matrix_mae.append(mean_absolute_error(test_image, train_image))\n",
        "      #matrix_msle.append(mean_squared_log_error(test_image, train_image))\n",
        "      #matrix_std.append(np.sqrt(mean_squared_error(test_image, train_image)))\n",
        "\n",
        "    estimations_mse.append(train_labels[np.argmin(matrix_mse)])\n",
        "    estimations_mae.append(train_labels[np.argmin(matrix_mae)])\n",
        "    #estimations_msle.append(train_labels[np.argmin(matrix_msle)])\n",
        "    #estimations_std.append(train_labels[np.argmin(matrix_std)])\n",
        "\n",
        "    train_images.append(train_matrix[np.argmin(matrix_mse)]) # for print\n",
        "\n",
        "  result_mse = np.equal(test_labels, estimations_mse)\n",
        "  result_mae = np.equal(test_labels, estimations_mae)\n",
        "  #result_msle = np.equal(test_labels, estimations_msle)\n",
        "  #result_std = np.equal(test_labels, estimations_std)\n",
        "\n",
        "  matrix_length = len(result_mse)\n",
        "\n",
        "  evaluation_mse = np.sum(result_mse)/matrix_length\n",
        "  evaluation_mae = np.sum(result_mae)/matrix_length\n",
        "  #evaluation_msle = np.sum(result_msle)/matrix_length\n",
        "  #evaluation_std = np.sum(result_std)/matrix_length\n",
        "\n",
        "  print('MSE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_mse))\n",
        "  print('MAE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_mae))\n",
        "  #print('MSLE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_msle))\n",
        "  #print('STD{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_std))\n",
        "\n",
        "  # print dataset distribution\n",
        "#  if dataset_shuffle:\n",
        "#    plt.hist(test_labels, bins=range(1, len(list(set(test_labels))) + 2))\n",
        "#    plt.yticks(np.arange(0, len(list(set(img_list))) + 1, 1))\n",
        "#    plt.show()\n",
        "  \n",
        "  if print_difference_photos:\n",
        "    for img_ind in range(1,len(result_mse)):\n",
        "      if result_mse[img_ind]==False:\n",
        "        img_src = test_matrix[img_ind].reshape(112,92)\n",
        "        print(\"Index {}, test:\", img_ind)\n",
        "        print(\"Index {}, train:\", img_ind)\n",
        "        img_train = train_images[img_ind].reshape(112,92)\n",
        "        plt.subplot(1,2,1),plt.imshow(img_src)\n",
        "        plt.title(\"Test photo\")\n",
        "        plt.subplot(1,2,2),plt.imshow(img_train)\n",
        "        plt.title(\"Train photo\")\n",
        "        plt.show()\n",
        "\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 48.  49.  45. ...  47.  46.  46.]\n",
            " [ 35.  36.  37. ... 144. 147. 143.]\n",
            " [103. 105. 104. ...  44.  38.  43.]\n",
            " ...\n",
            " [108. 105. 104. ...  72.  73.  48.]\n",
            " [ 89.  87.  92. ...  93. 112. 109.]\n",
            " [125. 124. 124. ...  36.  35.  34.]]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-7ead5c2038f5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[0;31m#print(dataset)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_along_axis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf_min_max\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;31m#for i in range(0, len(dataset_avg)):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/shape_base.py\u001b[0m in \u001b[0;36mapply_along_axis\u001b[0;34m(func1d, axis, arr, *args, **kwargs)\u001b[0m\n\u001b[1;32m    377\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Cannot apply_along_axis when any iteration dimensions are 0'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m     \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minarr_view\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m     \u001b[0;31m# build a buffer for storing evaluations of func1d.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-20-7ead5c2038f5>\u001b[0m in \u001b[0;36mf_min_max\u001b[0;34m(a)\u001b[0m\n\u001b[1;32m     55\u001b[0m   \u001b[0mmax_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m   \u001b[0mavg_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Min {}, Max {}\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mx_min\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_max\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvectorized_f_0_1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maverage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'x_min' is not defined"
          ]
        }
      ]
    }
  ]
}