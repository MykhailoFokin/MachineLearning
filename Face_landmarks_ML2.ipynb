{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Face_landmarks_ML2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MykhailoFokin/MachineLearning/blob/Dev/Face_landmarks_ML2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DiBM__uGPHuo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "7f7e839e-a256-4cec-eb0d-596e1e584ea6"
      },
      "source": [
        "#Copy images repo\n",
        "!git clone https://github.com/SilvesterHsu/ORLFaceRecognition-PCA.git\n",
        "\n",
        "#Copy shape_predictor_68_face_landmarks.dat file\n",
        "import urllib.request\n",
        "urllib.request.urlretrieve('http://dlib.net/files/shape_predictor_68_face_landmarks.dat.bz2', 'shape_predictor_68_face_landmarks.dat.bz2')\n",
        "\n",
        "#Uncompress file\n",
        "import bz2,shutil\n",
        "\n",
        "with bz2.BZ2File(\"shape_predictor_68_face_landmarks.dat.bz2\") as fr, open(\"shape_predictor_68_face_landmarks.dat\",\"wb\") as fw:\n",
        "    shutil.copyfileobj(fr,fw)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ORLFaceRecognition-PCA'...\n",
            "remote: Enumerating objects: 604, done.\u001b[K\n",
            "remote: Total 604 (delta 0), reused 0 (delta 0), pack-reused 604\u001b[K\n",
            "Receiving objects: 100% (604/604), 3.59 MiB | 5.22 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2JwrPAkBTv2_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Initialize simple XML fuction\n",
        "def dict2xml(d, root_node=None):\n",
        "\twrap          =     False if None == root_node or isinstance(d, list) else True\n",
        "\troot          = 'objects' if None == root_node else root_node\n",
        "\troot_singular = root[:-1] if 's' == root[-1] and None == root_node else root\n",
        "\txml           = ''\n",
        "\tchildren      = []\n",
        "\n",
        "\tif isinstance(d, dict):\n",
        "\t\tfor key, value in dict.items(d):\n",
        "\t\t\tif isinstance(value, dict):\n",
        "\t\t\t\tchildren.append(dict2xml(value, key))\n",
        "\t\t\telif isinstance(value, list):\n",
        "\t\t\t\tchildren.append(dict2xml(value, key))\n",
        "\t\t\telse:\n",
        "\t\t\t\txml = xml + ' ' + key + '=\"' + str(value) + '\"'\n",
        "\telse:\n",
        "\t\tfor value in d:\n",
        "\t\t\tchildren.append(dict2xml(value, root_singular))\n",
        "\n",
        "\tend_tag = '>' if 0 < len(children) else '/>'\n",
        "\n",
        "\tif wrap or isinstance(d, dict):\n",
        "\t\txml = '<' + root + xml + end_tag\n",
        "\n",
        "\tif 0 < len(children):\n",
        "\t\tfor child in children:\n",
        "\t\t\txml = xml + child\n",
        "\n",
        "\t\tif wrap or isinstance(d, dict):\n",
        "\t\t\txml = xml + '</' + root + '>'\n",
        "\t\t\n",
        "\treturn xml"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LQSrSO6ZX3Qd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ORL database\n",
        "# https://github.com/SilvesterHsu/ORLFaceRecognition-PCA/tree/origin/master/att_faces\n",
        "\n",
        "# dlib face landmark detection example\n",
        "# http://dlib.net/face_landmark_detection.py.html\n",
        "\n",
        "# 68 face landmarks annotations\n",
        "# https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/\n",
        "\n",
        "# Example of result\n",
        "\"\"\"\n",
        "[\n",
        "  {\n",
        "    \"img\": \"s1/1.pgm\"\n",
        "    \"left_eye_x\": 20,\n",
        "    \"left_eye_y\": 52,\n",
        "    \"right_eye_x\": 69,\n",
        "    \"right_eye_y\": 51\n",
        "  }\n",
        "]\n",
        "\"\"\"\n",
        "import os\n",
        "import fnmatch\n",
        "import json\n",
        "import cv2\n",
        "import dlib\n",
        "import matplotlib.pyplot as plt\n",
        "from google.colab import drive\n",
        "from google.colab import files as gfile\n",
        "%matplotlib inline\n",
        "\n",
        "# drive.mount('/content/drive', force_remount=True)\n",
        "\n",
        "images_matrix = []\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')\n",
        "\n",
        "# read folder structure with files and put it to collection\n",
        "folder = []\n",
        "for i in os.walk(os.path.join('ORLFaceRecognition-PCA','att_faces')):\n",
        "  folder.append(i)\n",
        "\n",
        "for address, dirs, files in folder:\n",
        "    \n",
        "    for filename in fnmatch.filter(files, '*.pgm'):\n",
        "\n",
        "      img = cv2.imread(os.path.join(address,filename))\n",
        "      gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "      \n",
        "      faces, scores, idx = detector.run(gray, 1, -0.6)\n",
        "\n",
        "      #faces = detector(gray,1)\n",
        "      for face in faces:\n",
        "        landmarks = predictor(gray, face)\n",
        "\n",
        "        x1 = landmarks.part(36).x\n",
        "        y1 = landmarks.part(36).y\n",
        "\n",
        "        x2 = landmarks.part(45).x\n",
        "        y2 = landmarks.part(45).y\n",
        "\n",
        "        #cv2.circle(img, (x1, y1), 2, (255, 0, 0), -1)\n",
        "        #cv2.circle(img, (x2, y2), 2, (255, 0, 0), -1)\n",
        "        #plt.imshow(img)\n",
        "\n",
        "        images_matrix.append({\"img\": os.path.join(address.replace('ORLFaceRecognition-PCA/att_faces/',''),filename),\n",
        "                              \"left_eye_x\": x1,\n",
        "                              \"left_eye_y\": y1,\n",
        "                              \"right_eye_x\": x2,\n",
        "                              \"right_eye_y\": y2\n",
        "                            })\n",
        "\n",
        "\n",
        "images_matrix.sort(key=lambda k : k['img'])\n",
        "#print(images_matrix)\n",
        "\n",
        "# Save as json into colab\n",
        "#with open(\"data_file.json\", \"w\") as write_file:\n",
        "#    json.dump(images_matrix, write_file)\n",
        "\n",
        "# Save as json into google drive\n",
        "#with open('/content/drive/My Drive/Colab Notebooks/file.txt', 'w') as f:\n",
        "#  json.dump(images_matrix, f)\n",
        "\n",
        "# Download file from colab to local computer\n",
        "#gfile.download(\"data_file.json\")\n",
        "\n",
        "# Save as XML to colab\n",
        "import re \n",
        "xml_title = \"Result\"\n",
        "xml_tag_pattern = re.compile(r'</?{}>'.format(xml_title))\n",
        "inner_xml = re.sub(xml_tag_pattern, '', ''.join(dict2xml(e, root_node='Image') for e in images_matrix))\n",
        "\n",
        "with open(\"data_file.xml\", \"w\") as write_file:\n",
        "    write_file.write('<{0}>{1}</{0}>'.format(xml_title, inner_xml))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}