{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "simple_classification_with_MSE.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MykhailoFokin/MachineLearning/blob/Dev/simple_classification_with_MSE.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iyPNlcb6nKgy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import cv2\n",
        "import fnmatch\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.metrics import mean_absolute_error\n",
        "from sklearn.metrics import mean_squared_log_error\n",
        "from sklearn.metrics import median_absolute_error\n",
        "from sklearn.metrics import explained_variance_score\n",
        "\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bVOSURUpYlBh",
        "colab_type": "code",
        "outputId": "a1d428e2-dde7-422a-9b67-60c2083c1f1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "#Copy images from repo to colab\n",
        "!git clone https://github.com/SilvesterHsu/ORLFaceRecognition-PCA.git"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'ORLFaceRecognition-PCA'...\n",
            "remote: Enumerating objects: 604, done.\u001b[K\n",
            "remote: Total 604 (delta 0), reused 0 (delta 0), pack-reused 604\u001b[K\n",
            "Receiving objects: 100% (604/604), 3.59 MiB | 5.47 MiB/s, done.\n",
            "Resolving deltas: 100% (93/93), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OeWSRAG2l6xx",
        "colab_type": "code",
        "outputId": "3188a102-d841-4a30-87e3-33b44a5c2251",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "# read folder structure with files and put it to collection\n",
        "folder = []\n",
        "for i in os.walk(os.path.join('ORLFaceRecognition-PCA','att_faces')):\n",
        "  folder.append(i)\n",
        "\n",
        "split_regexp = [r'[0]*',r'[0|9]*',r'[0|8-9]*',r'[0|7-9]*',r'[0|6-9]*',r'[0|5-9]*',r'[0|4-9]*',r'[0|3-9]*',r'[0|2-9]*']\n",
        "\n",
        "for split_index in range(1, 10):\n",
        "\n",
        "  test_matrix = []\n",
        "  train_matrix = []\n",
        "\n",
        "  test_labels = []\n",
        "  train_labels = []\n",
        "\n",
        "  for address, dirs, files in folder:\n",
        "      \n",
        "      for filename in fnmatch.filter(files, '*.pgm'):\n",
        "\n",
        "        img = cv2.imread(os.path.join(address,filename))\n",
        "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n",
        "        gray.flatten().reshape(1, 10304)\n",
        "        person = address.replace('ORLFaceRecognition-PCA/att_faces/','')\n",
        "\n",
        "        # r'[0|8-9]*'\n",
        "        if fnmatch.filter(filename, r'[0|9]*'):\n",
        "          test_matrix.append(gray.flatten().reshape(1, 10304))\n",
        "          test_labels.append(person)\n",
        "        else:\n",
        "        #if fnmatch.filter(filename, r'[1-5]*'):\n",
        "          train_matrix.append(gray.flatten().reshape(1, 10304))\n",
        "          train_labels.append(person)\n",
        "\n",
        "  np_test_matrix = np.array(test_matrix)\n",
        "  np_train_matrix = np.array(train_matrix)\n",
        "    \n",
        "  # Different deviation results\n",
        "  result_mse = np.empty((len(np_train_matrix),1))     # mean_squared_error\n",
        "  result_mae = np.empty((len(np_train_matrix),1))     # mean_absolute_error\n",
        "  result_msle = np.empty((len(np_train_matrix),1))    # mean_squared_log_error\n",
        "  result_evs = np.empty((len(np_train_matrix),1))     # explained_variance_score\n",
        "  result_std = np.empty((len(np_train_matrix),1))     # standart deviance\n",
        "\n",
        "  predictions = np.empty((len(np_test_matrix),6),dtype=\"S3\") \n",
        "\n",
        "  estimations_mse = np.empty((len(np_test_matrix),1)) \n",
        "  estimations_mae = np.empty((len(np_test_matrix),1)) \n",
        "  estimations_msle = np.empty((len(np_test_matrix),1)) \n",
        "  estimations_evs = np.empty((len(np_test_matrix),1)) \n",
        "  estimations_std = np.empty((len(np_test_matrix),1))\n",
        "\n",
        "  for i in range(len(np_test_matrix)):\n",
        "    \n",
        "    for j in range(len(np_train_matrix)):\n",
        "      result_mse[j] = mean_squared_error(np_test_matrix[i], np_train_matrix[j])\n",
        "      result_mae[j] = mean_absolute_error(np_test_matrix[i], np_train_matrix[j])\n",
        "      result_msle[j] = mean_squared_log_error(np_test_matrix[i], np_train_matrix[j])\n",
        "      result_evs[j] = explained_variance_score(np_test_matrix[i], np_train_matrix[j])\n",
        "      result_std[j] = np.sqrt(mean_squared_error(np_test_matrix[i], np_train_matrix[j]))\n",
        "    \n",
        "    # write source labes with predicted ones\n",
        "    # comparing predicted and source label in estimation array\n",
        "    #print(train_labels[np.argmin(result_mse)])\n",
        "    predictions[i][0] = test_labels[i]\n",
        "    predictions[i][1] = train_labels[np.argmin(result_mse)]\n",
        "    predictions[i][2] = train_labels[np.argmin(result_mae)]\n",
        "    predictions[i][3] = train_labels[np.argmin(result_msle)]\n",
        "    predictions[i][4] = train_labels[np.argmin(result_evs)]\n",
        "    predictions[i][5] = train_labels[np.argmin(result_std)]\n",
        "\n",
        "    estimations_mse[i] = int(test_labels[i]==train_labels[np.argmin(result_mse)])\n",
        "    estimations_mae[i] = int(test_labels[i]==train_labels[np.argmin(result_mae)])\n",
        "    estimations_msle[i] = int(test_labels[i]==train_labels[np.argmin(result_msle)])\n",
        "    estimations_evs[i] = int(test_labels[i]==train_labels[np.argmin(result_evs)])\n",
        "    estimations_std[i] = int(test_labels[i]==train_labels[np.argmin(result_std)])\n",
        "\n",
        "  #print(predictions)\n",
        "  estimation_result_mse = estimations_mse.sum()/len(estimations_mse)\n",
        "  estimation_result_mae = estimations_mae.sum()/len(estimations_mae)\n",
        "  estimation_result_msle = estimations_msle.sum()/len(estimations_msle)\n",
        "  estimation_result_evs = estimations_evs.sum()/len(estimations_evs)\n",
        "  estimation_result_std = estimations_std.sum()/len(estimations_std)\n",
        "\n",
        "  #print(\"Estimation for MSE: {} ; MAE: {} ; MSLE: {} ; EVS: {} ; STD: {} ;\"\n",
        "  #.format(estimation_result_mse, estimation_result_mae, estimation_result_msle, estimation_result_evs, estimation_result_std))\n",
        "\n",
        "  #print(\"MSE: {}\", estimation_result_mse)\n",
        "  #print(\"MAE: {}\", estimation_result_mae)\n",
        "  #print(\"MSLE: {}\", estimation_result_msle)\n",
        "  #print(\"EVS: {}\", estimation_result_evs)\n",
        "  #print(\"STD: {}\", estimation_result_std)\n",
        "\n",
        "  SCORES = dict(mean_squared_error       = estimation_result_mse,\n",
        "                mean_absolute_error      = estimation_result_mae,\n",
        "                mean_squared_log_error   = estimation_result_msle,\n",
        "                explained_variance_score = estimation_result_evs,\n",
        "                standart_square_deviance = estimation_result_std)\n",
        "\n",
        "  print(\"Test {} percents to Train {} percents\",split_index*10,(10-split_index)*10)\n",
        "  print(SCORES)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE: {} 1.0\n",
            "MAE: {} 0.075\n",
            "MSLE: {} 0.925\n",
            "EVS: {} 0.025\n",
            "STD: {} 1.0\n",
            "{'mean_squared_error': 1.0, 'mean_absolute_error': 0.075, 'mean_squared_log_error': 0.925, 'explained_variance_score': 0.025, 'standart_square_deviance': 1.0}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4mtTesG2RiJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e46b247c-e068-4bcf-a02f-40f7622c21e5"
      },
      "source": [
        "dataset = []\n",
        "indexes = []\n",
        "test_matrix = []\n",
        "train_matrix = []\n",
        "test_labels = []\n",
        "train_labels = []\n",
        "dataset_shuffle = False\n",
        "stratify = None\n",
        "random_state = 42\n",
        "path_x=[]\n",
        "\n",
        "#print('MSE{}.  Train/Test : {:d} '.format('SJFSAFASF' if dataset_shuffle else '',random_state))\n",
        "\n",
        "#includes = r'|'.join([fnmatch.translate(x) for x in includes])\n",
        "\n",
        "# read folder structure with files and put it to collection\n",
        "folder = []\n",
        "for i in os.walk(os.path.join('ORLFaceRecognition-PCA','att_faces')):\n",
        "  folder.append(i)\n",
        "\n",
        "for address, dirs, files in folder:\n",
        "  for file in fnmatch.filter(files, '*.pgm'):\n",
        "    path_x.append(os.path.join(address,file))\n",
        "\n",
        "for file in sorted(path_x, key=lambda x: int(x.split(\"/\",3)[3].rstrip('.pgm')+x.split(\"/\",3)[2].lstrip(\"s\").zfill(2))):\n",
        "\n",
        "  img = cv2.imread(file)\n",
        "  gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)    \n",
        "  gray.flatten().reshape(1, 10304)\n",
        "  person = file.split(\"/\",3)[2].lstrip(\"s\")\n",
        "\n",
        "  dataset.append(gray.flatten().reshape(1, 10304))\n",
        "  indexes.append(int(person))\n",
        "\n",
        "for split_mark in range(1, 19):\n",
        "\n",
        "  if split_mark>=10:\n",
        "    dataset_shuffle = True\n",
        "    split_k=split_mark-9\n",
        "  else:\n",
        "    split_k=split_mark\n",
        "\n",
        "  train_matrix, test_matrix, train_labels, test_labels = train_test_split(dataset, indexes, test_size=0.1*split_k, random_state=random_state, shuffle=dataset_shuffle, stratify=stratify)\n",
        "\n",
        "  estimations_mse = []\n",
        "  estimations_mae = []\n",
        "  estimations_msle = []\n",
        "  estimations_std = []\n",
        "\n",
        "  for test_image in test_matrix:\n",
        "\n",
        "    matrix_mse = []\n",
        "    matrix_mae = []\n",
        "    matrix_msle = []\n",
        "    matrix_std = []\n",
        "\n",
        "    for train_image in train_matrix:\n",
        "\n",
        "      matrix_mse.append(mean_squared_error(test_image, train_image))\n",
        "      matrix_mae.append(mean_absolute_error(test_image, train_image))\n",
        "      matrix_msle.append(mean_squared_log_error(test_image, train_image))\n",
        "      matrix_std.append(np.sqrt(mean_squared_error(test_image, train_image)))\n",
        "\n",
        "    estimations_mse.append(train_labels[np.argmin(matrix_mse)])\n",
        "    estimations_mae.append(train_labels[np.argmin(matrix_mae)])\n",
        "    estimations_msle.append(train_labels[np.argmin(matrix_msle)])\n",
        "    estimations_std.append(train_labels[np.argmin(matrix_std)])\n",
        "\n",
        "  result_mse = np.equal(test_labels, estimations_mse)\n",
        "  result_mae = np.equal(test_labels, estimations_mae)\n",
        "  result_msle = np.equal(test_labels, estimations_msle)\n",
        "  result_std = np.equal(test_labels, estimations_std)\n",
        "\n",
        "  matrix_length = len(result_mse)\n",
        "\n",
        "  evaluation_mse = np.sum(result_mse)/matrix_length\n",
        "  evaluation_mae = np.sum(result_mae)/matrix_length\n",
        "  evaluation_msle = np.sum(result_msle)/matrix_length\n",
        "  evaluation_std = np.sum(result_std)/matrix_length\n",
        "\n",
        "  print('MSE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_mse))\n",
        "  print('MAE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_mae))\n",
        "  print('MSLE{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_msle))\n",
        "  print('STD{:s}.  Train/Test : {:d} / {:d} - {:.3f}'.format(' with Shuffle' if dataset_shuffle else '',100-split_k*10, split_k*10, evaluation_std))\n",
        "  #print('MAE.  Train/Test : %d / %d - %.3f' % (100-split_k*10, split_k*10, evaluation_mae))\n",
        "  #print('MSLE. Train/Test : %d / %d - %.3f' % (100-split_k*10, split_k*10, evaluation_msle))\n",
        "  #print('STD.  Train/Test : %d / %d - %.3f' % (100-split_k*10, split_k*10, evaluation_std))\n"
      ],
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MSE.  Train/Test : 90 / 10 - 1.000\n",
            "MAE.  Train/Test : 90 / 10 - 0.075\n",
            "MSLE.  Train/Test : 90 / 10 - 0.925\n",
            "STD.  Train/Test : 90 / 10 - 1.000\n",
            "MSE.  Train/Test : 80 / 20 - 1.000\n",
            "MAE.  Train/Test : 80 / 20 - 0.075\n",
            "MSLE.  Train/Test : 80 / 20 - 0.963\n",
            "STD.  Train/Test : 80 / 20 - 1.000\n",
            "MSE.  Train/Test : 70 / 30 - 1.000\n",
            "MAE.  Train/Test : 70 / 30 - 0.066\n",
            "MSLE.  Train/Test : 70 / 30 - 0.950\n",
            "STD.  Train/Test : 70 / 30 - 1.000\n",
            "MSE.  Train/Test : 60 / 40 - 1.000\n",
            "MAE.  Train/Test : 60 / 40 - 0.081\n",
            "MSLE.  Train/Test : 60 / 40 - 0.938\n",
            "STD.  Train/Test : 60 / 40 - 1.000\n",
            "MSE.  Train/Test : 50 / 50 - 0.930\n",
            "MAE.  Train/Test : 50 / 50 - 0.080\n",
            "MSLE.  Train/Test : 50 / 50 - 0.910\n",
            "STD.  Train/Test : 50 / 50 - 0.930\n",
            "MSE.  Train/Test : 40 / 60 - 0.846\n",
            "MAE.  Train/Test : 40 / 60 - 0.062\n",
            "MSLE.  Train/Test : 40 / 60 - 0.892\n",
            "STD.  Train/Test : 40 / 60 - 0.846\n",
            "MSE.  Train/Test : 30 / 70 - 0.814\n",
            "MAE.  Train/Test : 30 / 70 - 0.071\n",
            "MSLE.  Train/Test : 30 / 70 - 0.850\n",
            "STD.  Train/Test : 30 / 70 - 0.814\n",
            "MSE.  Train/Test : 20 / 80 - 0.806\n",
            "MAE.  Train/Test : 20 / 80 - 0.053\n",
            "MSLE.  Train/Test : 20 / 80 - 0.822\n",
            "STD.  Train/Test : 20 / 80 - 0.806\n",
            "MSE.  Train/Test : 10 / 90 - 0.694\n",
            "MAE.  Train/Test : 10 / 90 - 0.075\n",
            "MSLE.  Train/Test : 10 / 90 - 0.706\n",
            "STD.  Train/Test : 10 / 90 - 0.694\n",
            "MSE with Shuffle.  Train/Test : 90 / 10 - 0.975\n",
            "MAE with Shuffle.  Train/Test : 90 / 10 - 0.050\n",
            "MSLE with Shuffle.  Train/Test : 90 / 10 - 0.975\n",
            "STD with Shuffle.  Train/Test : 90 / 10 - 0.975\n",
            "MSE with Shuffle.  Train/Test : 80 / 20 - 0.963\n",
            "MAE with Shuffle.  Train/Test : 80 / 20 - 0.075\n",
            "MSLE with Shuffle.  Train/Test : 80 / 20 - 0.975\n",
            "STD with Shuffle.  Train/Test : 80 / 20 - 0.963\n",
            "MSE with Shuffle.  Train/Test : 70 / 30 - 0.967\n",
            "MAE with Shuffle.  Train/Test : 70 / 30 - 0.083\n",
            "MSLE with Shuffle.  Train/Test : 70 / 30 - 0.983\n",
            "STD with Shuffle.  Train/Test : 70 / 30 - 0.967\n",
            "MSE with Shuffle.  Train/Test : 60 / 40 - 0.969\n",
            "MAE with Shuffle.  Train/Test : 60 / 40 - 0.094\n",
            "MSLE with Shuffle.  Train/Test : 60 / 40 - 0.950\n",
            "STD with Shuffle.  Train/Test : 60 / 40 - 0.969\n",
            "MSE with Shuffle.  Train/Test : 50 / 50 - 0.955\n",
            "MAE with Shuffle.  Train/Test : 50 / 50 - 0.070\n",
            "MSLE with Shuffle.  Train/Test : 50 / 50 - 0.930\n",
            "STD with Shuffle.  Train/Test : 50 / 50 - 0.955\n",
            "MSE with Shuffle.  Train/Test : 40 / 60 - 0.921\n",
            "MAE with Shuffle.  Train/Test : 40 / 60 - 0.062\n",
            "MSLE with Shuffle.  Train/Test : 40 / 60 - 0.905\n",
            "STD with Shuffle.  Train/Test : 40 / 60 - 0.921\n",
            "MSE with Shuffle.  Train/Test : 30 / 70 - 0.875\n",
            "MAE with Shuffle.  Train/Test : 30 / 70 - 0.043\n",
            "MSLE with Shuffle.  Train/Test : 30 / 70 - 0.836\n",
            "STD with Shuffle.  Train/Test : 30 / 70 - 0.875\n",
            "MSE with Shuffle.  Train/Test : 20 / 80 - 0.713\n",
            "MAE with Shuffle.  Train/Test : 20 / 80 - 0.062\n",
            "MSLE with Shuffle.  Train/Test : 20 / 80 - 0.719\n",
            "STD with Shuffle.  Train/Test : 20 / 80 - 0.713\n",
            "MSE with Shuffle.  Train/Test : 10 / 90 - 0.539\n",
            "MAE with Shuffle.  Train/Test : 10 / 90 - 0.061\n",
            "MSLE with Shuffle.  Train/Test : 10 / 90 - 0.569\n",
            "STD with Shuffle.  Train/Test : 10 / 90 - 0.539\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}